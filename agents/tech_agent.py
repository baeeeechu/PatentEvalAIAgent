"""
ê¸°ìˆ ì„± í‰ê°€ ì—ì´ì „íŠ¸ v5.0 - ì •ëŸ‰í‰ê°€ ì¤‘ì‹¬ + Binary ì²´í¬ë¦¬ìŠ¤íŠ¸
- ì •ëŸ‰í‰ê°€ 60% + ì •ì„±í‰ê°€(LLM) 40%
- 32ê°œ í‰ê°€ìš”ì†Œ ì¤‘ ê¸°ìˆ ì„± 3ê°œ ì™„ì „ êµ¬í˜„: X7, X8, X9
- êµ¬ì¡°ë°©ì •ì‹ ëª¨ë¸ ì ìš©
- PDF ì›ë¬¸ ê¸°ë°˜ (í•˜ë“œì½”ë”© ì œê±°)
"""
import os
import json
from pathlib import Path
from typing import Dict, Any

from langchain_openai import ChatOpenAI


class TechnologyAgent:
    """ê¸°ìˆ ì„± í‰ê°€ ì—ì´ì „íŠ¸ v5.0"""
    
    def __init__(self, model_name: str = "gpt-4o-mini"):
        self.llm = ChatOpenAI(
            model=model_name,
            temperature=0.1,
            api_key=os.getenv("OPENAI_API_KEY")
        )
        
        # í”„ë¡¬í”„íŠ¸ ë¡œë“œ
        prompt_path = Path("prompts/tech_eval.txt")
        if prompt_path.exists():
            with open(prompt_path, "r", encoding="utf-8") as f:
                self.prompt_template = f.read()
        else:
            raise FileNotFoundError(f"í”„ë¡¬í”„íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {prompt_path}")
    
    def evaluate(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """ê¸°ìˆ ì„± í‰ê°€ ìˆ˜í–‰"""
        print("\nğŸ”¬ ê¸°ìˆ ì„± í‰ê°€ ì¤‘...")
        
        patent_path = state["current_patent"]
        patent_info = state["patent_info"][patent_path]
        rag_manager = state["rag_manager"]
        
        print(f"   ğŸ“„ í‰ê°€ ëŒ€ìƒ: {patent_info.get('title', 'N/A')[:50]}...")
        
        # === 1ë‹¨ê³„: ì •ëŸ‰ ì§€í‘œ ê³„ì‚° (X7, X8, X9) ===
        print("   ğŸ“Š ì •ëŸ‰ ì§€í‘œ ê³„ì‚° ì¤‘...")
        quantitative_metrics = self._calculate_quantitative_metrics(patent_info)
        
        print(f"      X7: ë„ë©´ ìˆ˜ = {quantitative_metrics['X7_drawing_count']}")
        print(f"      X8: ë°œëª…ëª…ì¹­ ê¸¸ì´ = {quantitative_metrics['X8_title_length']}ì")
        print(f"      X9: ì²­êµ¬í•­ ê³„ì—´ ìˆ˜ = {quantitative_metrics['X9_claim_series']}")
        
        # === 2ë‹¨ê³„: Binary ì²´í¬ë¦¬ìŠ¤íŠ¸ ===
        binary_checklist = self._binary_checklist(quantitative_metrics)
        
        print(f"   âœ… Binary ì²´í¬ë¦¬ìŠ¤íŠ¸:")
        for key, value in binary_checklist.items():
            status = "âœ“" if value else "âœ—"
            print(f"      {status} {key}")
        
        # === 3ë‹¨ê³„: ì •ëŸ‰ ì ìˆ˜ ê³„ì‚° (êµ¬ì¡°ë°©ì •ì‹ ëª¨ë¸) ===
        print("   ğŸ”¢ ì •ëŸ‰ ì ìˆ˜ ê³„ì‚° ì¤‘ (êµ¬ì¡°ë°©ì •ì‹)...")
        quantitative_score = self._calculate_quantitative_score(quantitative_metrics)
        
        print(f"      â€¢ ë„ë©´ ì ìˆ˜: {quantitative_score['drawing_score']:.1f}")
        print(f"      â€¢ ëª…ì¹­ ì ìˆ˜: {quantitative_score['title_score']:.1f}")
        print(f"      â€¢ ê³„ì—´ ì ìˆ˜: {quantitative_score['series_score']:.1f}")
        print(f"      âœ ì •ëŸ‰ ì ìˆ˜: {quantitative_score['total']:.1f}/100")
        
        # === 4ë‹¨ê³„: LLM ì •ì„± í‰ê°€ (ë³´ì¡°) ===
        print("   ğŸ¤– LLM ì •ì„± í‰ê°€ ì¤‘ (40%)...")
        
        rag_context = rag_manager.get_patent_summary(patent_path, max_chunks=10)
        
        prompt = self.prompt_template.format(
            patent_number=patent_info.get('number', 'N/A'),
            patent_title=patent_info.get('title', 'N/A'),
            applicant=patent_info.get('applicant', 'N/A'),
            quantitative_metrics=json.dumps(quantitative_metrics, indent=2, ensure_ascii=False),
            quantitative_score=json.dumps(quantitative_score, indent=2, ensure_ascii=False),
            binary_checklist=json.dumps(binary_checklist, indent=2, ensure_ascii=False),
            patent_summary=rag_context[:3000],
            rag_context=rag_context[:2000]
        )
        
        response = self.llm.invoke(prompt)
        qualitative_result = self._parse_response(response.content)
        
        qualitative_score = qualitative_result.get('qualitative_score', 60)
        
        print(f"      âœ ì •ì„± ì ìˆ˜: {qualitative_score:.1f}/100")
        
        # === 5ë‹¨ê³„: ìµœì¢… ì ìˆ˜ ê³„ì‚° (ì •ëŸ‰ 60% + ì •ì„± 40%) ===
        tech_score = quantitative_score['total'] * 0.6 + qualitative_score * 0.4
        
        print(f"   âœ… ê¸°ìˆ ì„± ìµœì¢… ì ìˆ˜: {tech_score:.1f}/100")
        print(f"      = ì •ëŸ‰({quantitative_score['total']:.1f}) Ã— 60%")
        print(f"      + ì •ì„±({qualitative_score:.1f}) Ã— 40%")
        
        # State ì—…ë°ì´íŠ¸
        state['tech_score'] = tech_score
        state['tech_quantitative'] = quantitative_score
        state['tech_qualitative'] = qualitative_result
        state['tech_metrics'] = quantitative_metrics
        state['tech_binary'] = binary_checklist
        state['tech_insights'] = self._format_insights(
            quantitative_metrics,
            quantitative_score,
            qualitative_result,
            tech_score
        )
        
        return state
    
    def _calculate_quantitative_metrics(self, patent_info: Dict) -> Dict:
        """ì •ëŸ‰ ì§€í‘œ ê³„ì‚° (X7, X8, X9)"""
        claims = patent_info.get('claims', [])
        
        # X7: ë„ë©´ ìˆ˜
        drawing_count = patent_info.get('drawing_count', 0)
        
        # X8: ë°œëª…ëª…ì¹­ ê¸¸ì´
        title_length = len(patent_info.get('title', ''))
        
        # X9: ì²­êµ¬í•­ ê³„ì—´ ìˆ˜ (ë…ë¦½í•­ ìˆ˜ë¡œ ì¶”ì •)
        independent_claims = self._classify_independent_claims(claims)
        claim_series = len(independent_claims)
        
        return {
            "X7_drawing_count": drawing_count,
            "X8_title_length": title_length,
            "X9_claim_series": claim_series,
        }
    
    def _classify_independent_claims(self, claims: list) -> list:
        """ë…ë¦½í•­ ì¶”ì¶œ"""
        independent = []
        
        dependent_patterns = [
            'ì œ', 'í•­ì—', 'ìˆì–´ì„œ', 'ì²­êµ¬í•­', 'ë˜ëŠ”', 'ë‚´ì§€'
        ]
        
        for claim in claims:
            is_dependent = any(pattern in claim[:50] for pattern in dependent_patterns)
            if not is_dependent:
                independent.append(claim)
        
        return independent if independent else claims[:1]  # ìµœì†Œ 1ê°œ
    
    def _binary_checklist(self, metrics: Dict) -> Dict[str, bool]:
        """Binary ì²´í¬ë¦¬ìŠ¤íŠ¸ (ê¸°ìˆ ì„± ê´€ë ¨)"""
        return {
            "has_sufficient_drawings": metrics['X7_drawing_count'] >= 3,
            "has_clear_title": 10 <= metrics['X8_title_length'] <= 100,
            "has_claim_series": metrics['X9_claim_series'] >= 1,
            "title_not_too_long": metrics['X8_title_length'] <= 100,
        }
    
    def _calculate_quantitative_score(self, metrics: Dict) -> Dict:
        """
        ì •ëŸ‰ ì ìˆ˜ ê³„ì‚° (êµ¬ì¡°ë°©ì •ì‹ ëª¨ë¸)
        
        ê¸°ìˆ ì„± = X7(ë„ë©´) Ã— 0.4 + X8(ëª…ì¹­) Ã— 0.3 + X9(ê³„ì—´) Ã— 0.3
        """
        
        # X7: ë„ë©´ ìˆ˜ ì ìˆ˜ (ìµœëŒ€ 40ì )
        # ê¸°ì¤€: 0ê°œ=0ì , 3ê°œ=20ì , 5ê°œ=30ì , 10ê°œ ì´ìƒ=40ì 
        drawing_count = metrics['X7_drawing_count']
        if drawing_count >= 10:
            drawing_score = 100
        elif drawing_count >= 5:
            drawing_score = 75
        elif drawing_count >= 3:
            drawing_score = 60
        elif drawing_count >= 1:
            drawing_score = 40
        else:
            drawing_score = 0
        
        # X8: ë°œëª…ëª…ì¹­ ê¸¸ì´ ì ìˆ˜ (ìµœëŒ€ 30ì )
        # ê¸°ì¤€: 20-80ì=100ì , 10-100ì=70ì , ê·¸ ì™¸=40ì 
        title_length = metrics['X8_title_length']
        if 20 <= title_length <= 80:
            title_score = 100
        elif 10 <= title_length <= 100:
            title_score = 70
        elif title_length > 0:
            title_score = 40
        else:
            title_score = 0
        
        # X9: ì²­êµ¬í•­ ê³„ì—´ ìˆ˜ ì ìˆ˜ (ìµœëŒ€ 30ì )
        # ê¸°ì¤€: 3ê°œ ì´ìƒ=100ì , 2ê°œ=70ì , 1ê°œ=40ì 
        claim_series = metrics['X9_claim_series']
        if claim_series >= 3:
            series_score = 100
        elif claim_series >= 2:
            series_score = 70
        elif claim_series >= 1:
            series_score = 40
        else:
            series_score = 0
        
        # ê°€ì¤‘ í•©ì‚°
        total_score = (
            drawing_score * 0.4 +
            title_score * 0.3 +
            series_score * 0.3
        )
        
        return {
            "drawing_score": drawing_score,
            "title_score": title_score,
            "series_score": series_score,
            "total": round(total_score, 1)
        }
    
    def _parse_response(self, content: str) -> Dict:
        """LLM ì‘ë‹µ íŒŒì‹±"""
        try:
            json_start = content.find('{')
            json_end = content.rfind('}') + 1
            
            if json_start != -1 and json_end > json_start:
                json_str = content[json_start:json_end]
                result = json.loads(json_str)
                return result
            else:
                print("âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨ - ê¸°ë³¸ê°’ ì‚¬ìš©")
                return self._default_qualitative_result()
        except json.JSONDecodeError as e:
            print(f"âš ï¸ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            return self._default_qualitative_result()
    
    def _default_qualitative_result(self) -> Dict:
        """ê¸°ë³¸ ì •ì„± í‰ê°€ ê²°ê³¼"""
        return {
            "qualitative_score": 60,
            "strengths": ["í‰ê°€ ì‹¤íŒ¨ - ê¸°ë³¸ê°’"],
            "weaknesses": ["í‰ê°€ ì‹¤íŒ¨ - ê¸°ë³¸ê°’"],
            "competitive_analysis": "í‰ê°€ ì‹¤íŒ¨",
            "rnd_recommendation": "í‰ê°€ ì‹¤íŒ¨"
        }
    
    def _format_insights(
        self,
        quantitative_metrics: Dict,
        quantitative_score: Dict,
        qualitative_result: Dict,
        final_score: float
    ) -> str:
        """í‰ê°€ ê²°ê³¼ë¥¼ Markdown í˜•ì‹ìœ¼ë¡œ í¬ë§·"""
        
        strengths = '\n'.join([f"- {s}" for s in qualitative_result.get('strengths', [])])
        weaknesses = '\n'.join([f"- {w}" for w in qualitative_result.get('weaknesses', [])])
        
        insights = f"""## ê¸°ìˆ ì„± í‰ê°€ ìƒì„¸ ê²°ê³¼

### ğŸ“Š ìµœì¢… ì ìˆ˜: {final_score:.1f}/100
- **ì •ëŸ‰ í‰ê°€** (60%): {quantitative_score['total']:.1f}ì 
- **ì •ì„± í‰ê°€** (40%): {qualitative_result.get('qualitative_score', 60):.1f}ì 

### ğŸ“ ì •ëŸ‰ ì§€í‘œ (PDF ì›ë¬¸ ê¸°ë°˜)
- **X7. ë„ë©´ ìˆ˜**: {quantitative_metrics['X7_drawing_count']}ê°œ â†’ {quantitative_score['drawing_score']:.1f}ì 
- **X8. ë°œëª…ëª…ì¹­ ê¸¸ì´**: {quantitative_metrics['X8_title_length']}ì â†’ {quantitative_score['title_score']:.1f}ì 
- **X9. ì²­êµ¬í•­ ê³„ì—´ ìˆ˜**: {quantitative_metrics['X9_claim_series']}ê°œ â†’ {quantitative_score['series_score']:.1f}ì 

### ğŸ”¢ êµ¬ì¡°ë°©ì •ì‹ ëª¨ë¸
```
ê¸°ìˆ ì„± = X7(ë„ë©´) Ã— 0.4 + X8(ëª…ì¹­) Ã— 0.3 + X9(ê³„ì—´) Ã— 0.3
       = {quantitative_score['drawing_score']:.1f} Ã— 0.4 + {quantitative_score['title_score']:.1f} Ã— 0.3 + {quantitative_score['series_score']:.1f} Ã— 0.3
       = {quantitative_score['total']:.1f}ì  (ì •ëŸ‰)

ìµœì¢… = ì •ëŸ‰({quantitative_score['total']:.1f}) Ã— 60% + ì •ì„±({qualitative_result.get('qualitative_score', 60):.1f}) Ã— 40%
     = {final_score:.1f}ì 
```

### âœ… ê°•ì  (LLM ì •ì„± í‰ê°€)
{strengths}

### âš ï¸ ì•½ì  (LLM ì •ì„± í‰ê°€)
{weaknesses}

### ğŸ” ê²½ìŸ ë¶„ì„
{qualitative_result.get('competitive_analysis', 'N/A')}

### ğŸ’¡ R&D ì œì–¸
{qualitative_result.get('rnd_recommendation', 'N/A')}
"""
        return insights


if __name__ == "__main__":
    print("ê¸°ìˆ ì„± í‰ê°€ ì—ì´ì „íŠ¸ v5.0 - ì •ëŸ‰í‰ê°€ ì¤‘ì‹¬")