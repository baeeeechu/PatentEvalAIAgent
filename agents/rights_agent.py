"""
ê¶Œë¦¬ì„± í‰ê°€ ì—ì´ì „íŠ¸ v5.0 - ì •ëŸ‰í‰ê°€ ì¤‘ì‹¬ + Binary ì²´í¬ë¦¬ìŠ¤íŠ¸
- ì •ëŸ‰í‰ê°€ 70% + ì •ì„±í‰ê°€(LLM) 30%
- 32ê°œ í‰ê°€ìš”ì†Œ ì¤‘ ê¶Œë¦¬ì„± 6ê°œ ì™„ì „ êµ¬í˜„: X1~X6
- êµ¬ì¡°ë°©ì •ì‹ ëª¨ë¸ ì ìš©
- PDF ì›ë¬¸ ê¸°ë°˜ (í•˜ë“œì½”ë”© ì œê±°)
"""
import os
import json
from pathlib import Path
from typing import Dict, Any, Tuple, List

from langchain_openai import ChatOpenAI


class RightsAgent:
    """ê¶Œë¦¬ì„± í‰ê°€ ì—ì´ì „íŠ¸ v5.0"""
    
    def __init__(self, model_name: str = "gpt-4o-mini"):
        self.llm = ChatOpenAI(
            model=model_name,
            temperature=0.1,
            api_key=os.getenv("OPENAI_API_KEY")
        )
        
        # í”„ë¡¬í”„íŠ¸ ë¡œë“œ
        prompt_path = Path("prompts/rights_eval.txt")
        if prompt_path.exists():
            with open(prompt_path, "r", encoding="utf-8") as f:
                self.prompt_template = f.read()
        else:
            raise FileNotFoundError(f"í”„ë¡¬í”„íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {prompt_path}")
    
    def evaluate(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """ê¶Œë¦¬ì„± í‰ê°€ ìˆ˜í–‰"""
        print("\nâš–ï¸  ê¶Œë¦¬ì„± í‰ê°€ ì¤‘...")
        
        patent_path = state["current_patent"]
        patent_info = state["patent_info"][patent_path]
        rag_manager = state["rag_manager"]
        
        print(f"   ğŸ“„ í‰ê°€ ëŒ€ìƒ: {patent_info.get('title', 'N/A')[:50]}...")
        
        # === 1ë‹¨ê³„: ì •ëŸ‰ ì§€í‘œ ê³„ì‚° (X1~X6) ===
        print("   ğŸ“Š ì •ëŸ‰ ì§€í‘œ ê³„ì‚° ì¤‘...")
        quantitative_metrics = self._calculate_quantitative_metrics(patent_info)
        
        print(f"      X1: IPC ìˆ˜ = {quantitative_metrics['X1_ipc_count']}")
        print(f"      X2: ë…ë¦½í•­ ìˆ˜ = {quantitative_metrics['X2_independent_claims']}")
        print(f"      X3: ì¢…ì†í•­ ìˆ˜ = {quantitative_metrics['X3_dependent_claims']}")
        print(f"      X4: ì „ì²´ ì²­êµ¬í•­ ìˆ˜ = {quantitative_metrics['X4_total_claims']}")
        print(f"      X5: ë…ë¦½í•­ í‰ê·  ê¸¸ì´ = {quantitative_metrics['X5_independent_avg_length']:.0f}ì")
        print(f"      X6: ì¢…ì†í•­ í‰ê·  ê¸¸ì´ = {quantitative_metrics['X6_dependent_avg_length']:.0f}ì")
        
        # === 2ë‹¨ê³„: Binary ì²´í¬ë¦¬ìŠ¤íŠ¸ ===
        binary_checklist = self._binary_checklist(quantitative_metrics)
        
        print(f"   âœ… Binary ì²´í¬ë¦¬ìŠ¤íŠ¸:")
        for key, value in binary_checklist.items():
            status = "âœ“" if value else "âœ—"
            print(f"      {status} {key}")
        
        # === 3ë‹¨ê³„: ì •ëŸ‰ ì ìˆ˜ ê³„ì‚° (êµ¬ì¡°ë°©ì •ì‹ ëª¨ë¸) ===
        print("   ğŸ”¢ ì •ëŸ‰ ì ìˆ˜ ê³„ì‚° ì¤‘ (êµ¬ì¡°ë°©ì •ì‹)...")
        quantitative_score = self._calculate_quantitative_score(quantitative_metrics)
        
        print(f"      â€¢ IPC ì ìˆ˜: {quantitative_score['ipc_score']:.1f}")
        print(f"      â€¢ ì²­êµ¬í•­ ê°œìˆ˜ ì ìˆ˜: {quantitative_score['claims_count_score']:.1f}")
        print(f"      â€¢ ì²­êµ¬í•­ ê¸¸ì´ ì ìˆ˜: {quantitative_score['claims_length_score']:.1f}")
        print(f"      â€¢ ê³„ì¸µ êµ¬ì¡° ì ìˆ˜: {quantitative_score['hierarchy_score']:.1f}")
        print(f"      âœ ì •ëŸ‰ ì ìˆ˜: {quantitative_score['total']:.1f}/100")
        
        # === 4ë‹¨ê³„: LLM ì •ì„± í‰ê°€ (ë³´ì¡°) ===
        print("   ğŸ¤– LLM ì •ì„± í‰ê°€ ì¤‘ (30%)...")
        
        rag_context = rag_manager.get_patent_summary(patent_path, max_chunks=8)
        
        prompt = self.prompt_template.format(
            patent_number=patent_info.get('number', 'N/A'),
            patent_title=patent_info.get('title', 'N/A'),
            applicant=patent_info.get('applicant', 'N/A'),
            claims_count=patent_info.get('claims_count', 0),
            ipc_codes=', '.join(patent_info.get('ipc_codes', [])[:3]),
            quantitative_metrics=json.dumps(quantitative_metrics, indent=2, ensure_ascii=False),
            quantitative_score=json.dumps(quantitative_score, indent=2, ensure_ascii=False),
            binary_checklist=json.dumps(binary_checklist, indent=2, ensure_ascii=False),
            patent_summary=rag_context[:3000],
            rag_context=rag_context[:2000]
        )
        
        response = self.llm.invoke(prompt)
        qualitative_result = self._parse_response(response.content)
        
        qualitative_score = qualitative_result.get('qualitative_score', 60)
        
        print(f"      âœ ì •ì„± ì ìˆ˜: {qualitative_score:.1f}/100")
        
        # === 5ë‹¨ê³„: ìµœì¢… ì ìˆ˜ ê³„ì‚° (ì •ëŸ‰ 70% + ì •ì„± 30%) ===
        rights_score = quantitative_score['total'] * 0.7 + qualitative_score * 0.3
        
        print(f"   âœ… ê¶Œë¦¬ì„± ìµœì¢… ì ìˆ˜: {rights_score:.1f}/100")
        print(f"      = ì •ëŸ‰({quantitative_score['total']:.1f}) Ã— 70%")
        print(f"      + ì •ì„±({qualitative_score:.1f}) Ã— 30%")
        
        # State ì—…ë°ì´íŠ¸
        state['rights_score'] = rights_score
        state['rights_quantitative'] = quantitative_score
        state['rights_qualitative'] = qualitative_result
        state['rights_metrics'] = quantitative_metrics
        state['rights_binary'] = binary_checklist
        state['rights_insights'] = self._format_insights(
            quantitative_metrics,
            quantitative_score,
            qualitative_result,
            rights_score
        )
        
        return state
    
    def _calculate_quantitative_metrics(self, patent_info: Dict) -> Dict:
        """ì •ëŸ‰ ì§€í‘œ ê³„ì‚° (X1~X6)"""
        claims = patent_info.get('claims', [])
        
        # ë…ë¦½í•­/ì¢…ì†í•­ ë¶„ë¥˜
        independent_claims, dependent_claims = self._classify_claims(claims)
        
        # X1: IPC ìˆ˜
        ipc_count = len(patent_info.get('ipc_codes', []))
        
        # X2: ë…ë¦½í•­ ìˆ˜
        independent_count = len(independent_claims)
        
        # X3: ì¢…ì†í•­ ìˆ˜
        dependent_count = len(dependent_claims)
        
        # X4: ì „ì²´ ì²­êµ¬í•­ ìˆ˜
        total_claims = patent_info.get('claims_count', 0)
        
        # X5: ë…ë¦½í•­ í‰ê·  ê¸¸ì´
        independent_avg_length = (
            sum(len(c) for c in independent_claims) / len(independent_claims)
            if independent_claims else 0
        )
        
        # X6: ì¢…ì†í•­ í‰ê·  ê¸¸ì´
        dependent_avg_length = (
            sum(len(c) for c in dependent_claims) / len(dependent_claims)
            if dependent_claims else 0
        )
        
        return {
            "X1_ipc_count": ipc_count,
            "X2_independent_claims": independent_count,
            "X3_dependent_claims": dependent_count,
            "X4_total_claims": total_claims,
            "X5_independent_avg_length": round(independent_avg_length, 1),
            "X6_dependent_avg_length": round(dependent_avg_length, 1),
        }
    
    def _classify_claims(self, claims: list) -> Tuple[List[str], List[str]]:
        """ì²­êµ¬í•­ì„ ë…ë¦½í•­/ì¢…ì†í•­ìœ¼ë¡œ ë¶„ë¥˜"""
        independent = []
        dependent = []
        
        # ì¢…ì†í•­ íŒ¨í„´
        dependent_patterns = [
            'ì œ', 'í•­ì—', 'ìˆì–´ì„œ', 'ì²­êµ¬í•­', 'ë˜ëŠ”', 'ë‚´ì§€'
        ]
        
        for claim in claims:
            # ì²« 50ì ë‚´ì— ì¢…ì†í•­ íŒ¨í„´ì´ ìˆëŠ”ì§€ í™•ì¸
            is_dependent = any(pattern in claim[:50] for pattern in dependent_patterns)
            
            if is_dependent:
                dependent.append(claim)
            else:
                independent.append(claim)
        
        # ìµœì†Œ 1ê°œì˜ ë…ë¦½í•­ ë³´ì¥
        if not independent and claims:
            independent = [claims[0]]
            dependent = claims[1:]
        
        return independent, dependent
    
    def _binary_checklist(self, metrics: Dict) -> Dict[str, bool]:
        """Binary ì²´í¬ë¦¬ìŠ¤íŠ¸ (ê¶Œë¦¬ì„± ê´€ë ¨)"""
        return {
            "has_multiple_ipc": metrics['X1_ipc_count'] >= 2,
            "has_sufficient_claims": metrics['X4_total_claims'] >= 10,
            "has_independent_claim": metrics['X2_independent_claims'] >= 1,
            "has_detailed_independent_claim": metrics['X5_independent_avg_length'] >= 100,
            "has_dependent_hierarchy": metrics['X3_dependent_claims'] >= metrics['X2_independent_claims'],
            "claims_length_balanced": (
                50 <= metrics['X6_dependent_avg_length'] <= metrics['X5_independent_avg_length']
                if metrics['X5_independent_avg_length'] > 0 else False
            ),
        }
    
    def _calculate_quantitative_score(self, metrics: Dict) -> Dict:
        """
        ì •ëŸ‰ ì ìˆ˜ ê³„ì‚° (êµ¬ì¡°ë°©ì •ì‹ ëª¨ë¸)
        
        ê¶Œë¦¬ì„± = IPC(25%) + ì²­êµ¬í•­ê°œìˆ˜(30%) + ì²­êµ¬í•­ê¸¸ì´(25%) + ê³„ì¸µêµ¬ì¡°(20%)
        """
        
        # 1. IPC ìˆ˜ ì ìˆ˜ (ìµœëŒ€ 25ì )
        # ê¸°ì¤€: 10ê°œ ì´ìƒ=100, 5ê°œ=75, 2ê°œ=60, 1ê°œ=40
        ipc_count = metrics['X1_ipc_count']
        if ipc_count >= 10:
            ipc_score = 100
        elif ipc_count >= 5:
            ipc_score = 75
        elif ipc_count >= 2:
            ipc_score = 60
        elif ipc_count >= 1:
            ipc_score = 40
        else:
            ipc_score = 0
        
        # 2. ì²­êµ¬í•­ ê°œìˆ˜ ì ìˆ˜ (ìµœëŒ€ 30ì )
        # ê¸°ì¤€: 30ê°œ ì´ìƒ=100, 20ê°œ=80, 10ê°œ=60, 5ê°œ=40
        total_claims = metrics['X4_total_claims']
        if total_claims >= 30:
            claims_count_score = 100
        elif total_claims >= 20:
            claims_count_score = 80
        elif total_claims >= 10:
            claims_count_score = 60
        elif total_claims >= 5:
            claims_count_score = 40
        else:
            claims_count_score = 20
        
        # 3. ì²­êµ¬í•­ ê¸¸ì´ ì ìˆ˜ (ìµœëŒ€ 25ì )
        # ë…ë¦½í•­: 200ì ì´ìƒ=100, 100ì=70, 50ì=40
        independent_length = metrics['X5_independent_avg_length']
        if independent_length >= 200:
            length_score = 100
        elif independent_length >= 100:
            length_score = 70
        elif independent_length >= 50:
            length_score = 40
        else:
            length_score = 20
        
        # 4. ê³„ì¸µ êµ¬ì¡° ì ìˆ˜ (ìµœëŒ€ 20ì )
        # ì¢…ì†í•­/ë…ë¦½í•­ ë¹„ìœ¨: 5 ì´ìƒ=100, 3=75, 1=50
        independent_count = metrics['X2_independent_claims']
        dependent_count = metrics['X3_dependent_claims']
        
        if independent_count > 0:
            ratio = dependent_count / independent_count
            if ratio >= 5:
                hierarchy_score = 100
            elif ratio >= 3:
                hierarchy_score = 75
            elif ratio >= 1:
                hierarchy_score = 50
            else:
                hierarchy_score = 30
        else:
            hierarchy_score = 0
        
        # ê°€ì¤‘ í•©ì‚°
        total_score = (
            ipc_score * 0.25 +
            claims_count_score * 0.30 +
            length_score * 0.25 +
            hierarchy_score * 0.20
        )
        
        return {
            "ipc_score": ipc_score,
            "claims_count_score": claims_count_score,
            "claims_length_score": length_score,
            "hierarchy_score": hierarchy_score,
            "total": round(total_score, 1)
        }
    
    def _parse_response(self, content: str) -> Dict:
        """LLM ì‘ë‹µ íŒŒì‹±"""
        try:
            json_start = content.find('{')
            json_end = content.rfind('}') + 1
            
            if json_start != -1 and json_end > json_start:
                json_str = content[json_start:json_end]
                result = json.loads(json_str)
                return result
            else:
                print("âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨ - ê¸°ë³¸ê°’ ì‚¬ìš©")
                return self._default_qualitative_result()
        except json.JSONDecodeError as e:
            print(f"âš ï¸ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            return self._default_qualitative_result()
    
    def _default_qualitative_result(self) -> Dict:
        """ê¸°ë³¸ ì •ì„± í‰ê°€ ê²°ê³¼"""
        return {
            "qualitative_score": 60,
            "strengths": ["í‰ê°€ ì‹¤íŒ¨ - ê¸°ë³¸ê°’"],
            "weaknesses": ["í‰ê°€ ì‹¤íŒ¨ - ê¸°ë³¸ê°’"],
            "legal_risk": "í‰ê°€ ì‹¤íŒ¨",
            "defense_strategy": "í‰ê°€ ì‹¤íŒ¨",
            "portfolio_fit": "í‰ê°€ ì‹¤íŒ¨"
        }
    
    def _format_insights(
        self,
        quantitative_metrics: Dict,
        quantitative_score: Dict,
        qualitative_result: Dict,
        final_score: float
    ) -> str:
        """í‰ê°€ ê²°ê³¼ë¥¼ Markdown í˜•ì‹ìœ¼ë¡œ í¬ë§·"""
        
        strengths = '\n'.join([f"- {s}" for s in qualitative_result.get('strengths', [])])
        weaknesses = '\n'.join([f"- {w}" for w in qualitative_result.get('weaknesses', [])])
        
        insights = f"""## ê¶Œë¦¬ì„± í‰ê°€ ìƒì„¸ ê²°ê³¼

### ğŸ“Š ìµœì¢… ì ìˆ˜: {final_score:.1f}/100
- **ì •ëŸ‰ í‰ê°€** (70%): {quantitative_score['total']:.1f}ì 
- **ì •ì„± í‰ê°€** (30%): {qualitative_result.get('qualitative_score', 60):.1f}ì 

### ğŸ“ ì •ëŸ‰ ì§€í‘œ (PDF ì›ë¬¸ ê¸°ë°˜)
- **X1. IPC ìˆ˜**: {quantitative_metrics['X1_ipc_count']}ê°œ â†’ {quantitative_score['ipc_score']:.1f}ì 
- **X2. ë…ë¦½í•­ ìˆ˜**: {quantitative_metrics['X2_independent_claims']}ê°œ
- **X3. ì¢…ì†í•­ ìˆ˜**: {quantitative_metrics['X3_dependent_claims']}ê°œ
- **X4. ì „ì²´ ì²­êµ¬í•­ ìˆ˜**: {quantitative_metrics['X4_total_claims']}ê°œ â†’ {quantitative_score['claims_count_score']:.1f}ì 
- **X5. ë…ë¦½í•­ í‰ê·  ê¸¸ì´**: {quantitative_metrics['X5_independent_avg_length']:.0f}ì â†’ {quantitative_score['claims_length_score']:.1f}ì 
- **X6. ì¢…ì†í•­ í‰ê·  ê¸¸ì´**: {quantitative_metrics['X6_dependent_avg_length']:.0f}ì

### ğŸ”¢ êµ¬ì¡°ë°©ì •ì‹ ëª¨ë¸
```
ê¶Œë¦¬ì„± = IPC(25%) + ì²­êµ¬í•­ê°œìˆ˜(30%) + ì²­êµ¬í•­ê¸¸ì´(25%) + ê³„ì¸µêµ¬ì¡°(20%)
       = {quantitative_score['ipc_score']:.1f} Ã— 0.25 + {quantitative_score['claims_count_score']:.1f} Ã— 0.30 
         + {quantitative_score['claims_length_score']:.1f} Ã— 0.25 + {quantitative_score['hierarchy_score']:.1f} Ã— 0.20
       = {quantitative_score['total']:.1f}ì  (ì •ëŸ‰)

ìµœì¢… = ì •ëŸ‰({quantitative_score['total']:.1f}) Ã— 70% + ì •ì„±({qualitative_result.get('qualitative_score', 60):.1f}) Ã— 30%
     = {final_score:.1f}ì 
```

### âœ… ê°•ì  (LLM ì •ì„± í‰ê°€)
{strengths}

### âš ï¸ ì•½ì  (LLM ì •ì„± í‰ê°€)
{weaknesses}

### âš–ï¸ ë²•ì  ë¦¬ìŠ¤í¬
{qualitative_result.get('legal_risk', 'N/A')}

### ğŸ›¡ï¸ ë°©ì–´ ì „ëµ
{qualitative_result.get('defense_strategy', 'N/A')}

### ğŸ“‚ í¬íŠ¸í´ë¦¬ì˜¤ ì í•©ì„±
{qualitative_result.get('portfolio_fit', 'N/A')}
"""
        return insights


if __name__ == "__main__":
    print("ê¶Œë¦¬ì„± í‰ê°€ ì—ì´ì „íŠ¸ v5.0 - ì •ëŸ‰í‰ê°€ ì¤‘ì‹¬")